<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Research(Technical) on JH Gu&#39;s Tech Blog</title>
        <link>https://gujh14.github.io/categories/researchtechnical/</link>
        <description>Recent content in Research(Technical) on JH Gu&#39;s Tech Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Tue, 22 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://gujh14.github.io/categories/researchtechnical/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Does GNN Pre-training Help Molecular Representation?</title>
        <link>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</link>
        <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/0.png" alt="Featured image of post Does GNN Pre-training Help Molecular Representation?" /&gt;&lt;p&gt;NeurIPS, &amp;lsquo;22
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2207.06010&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/abs/2207.06010&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised pre-training alone &lt;strong&gt;does not&lt;/strong&gt; provide statistically significant improvements over non-pre-trained methods on downstream tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data splits, hand-crafted rich features, or hyperparameters&lt;/strong&gt; can bring significant improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled.png&#34;
	width=&#34;1722&#34;
	height=&#34;582&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;710px&#34;
	
&gt;
Pre-train objectives&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised
&lt;ul&gt;
&lt;li&gt;Node prediction&lt;/li&gt;
&lt;li&gt;Context prediction&lt;/li&gt;
&lt;li&gt;Motif prediction&lt;/li&gt;
&lt;li&gt;Contrastive learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supervised
&lt;ul&gt;
&lt;li&gt;Related tasks with label (e.g. ChEMBL dataset)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graph features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Basic
Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1905.12265&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hu et al.&lt;/a&gt;&lt;br&gt;
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1.png&#34;
	width=&#34;1694&#34;
	height=&#34;508&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;333&#34;
		data-flex-basis=&#34;800px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich&lt;/p&gt;
&lt;p&gt;Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2007.02835&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rong et al.&lt;/a&gt; This is the superset of basic features.
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2.png&#34;
	width=&#34;1338&#34;
	height=&#34;1076&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;124&#34;
		data-flex-basis=&#34;298px&#34;
	
&gt;
In downstream tasks, additional 2d normalized &lt;code&gt;rdNormalizedDescriptors&lt;/code&gt; are used (not in pre-training).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Downstream splits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Scaffold&lt;/p&gt;
&lt;p&gt;Sorts the molecule according to the scaffold, then partition the sorted list into train/valid/test splits. → Deterministic&lt;/p&gt;
&lt;p&gt;Molecules of each set are most different ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Balanced scaffold&lt;/p&gt;
&lt;p&gt;Introduces the randomness in the sorting and splitting stages of Scaffold split.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GNN architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GIN&lt;/li&gt;
&lt;li&gt;GraphSAGE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pre-train dataset&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ZINC15 (self-supervised)&lt;/p&gt;
&lt;p&gt;2 million molecules. Pre-processed following Hu et al.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SAVI (self-supervised)&lt;/p&gt;
&lt;p&gt;1 billion drug-like molecules synthesized by computer simulated reactions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChEMBL (supervised)&lt;/p&gt;
&lt;p&gt;500k drugable molecules with 1,310 prediction target labels from bio-activity assays.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3.png&#34;
	width=&#34;1696&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;421&#34;
		data-flex-basis=&#34;1012px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4.png&#34;
	width=&#34;1694&#34;
	height=&#34;306&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;553&#34;
		data-flex-basis=&#34;1328px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5.png&#34;
	width=&#34;1690&#34;
	height=&#34;390&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;433&#34;
		data-flex-basis=&#34;1040px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6.png&#34;
	width=&#34;1712&#34;
	height=&#34;308&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6_hu9e3333a7416211da0979291a20928457_104323_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6_hu9e3333a7416211da0979291a20928457_104323_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;555&#34;
		data-flex-basis=&#34;1334px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7.png&#34;
	width=&#34;1700&#34;
	height=&#34;326&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;521&#34;
		data-flex-basis=&#34;1251px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8.png&#34;
	width=&#34;1702&#34;
	height=&#34;316&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;538&#34;
		data-flex-basis=&#34;1292px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9.png&#34;
	width=&#34;1710&#34;
	height=&#34;324&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;527&#34;
		data-flex-basis=&#34;1266px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10.png&#34;
	width=&#34;1696&#34;
	height=&#34;328&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;517&#34;
		data-flex-basis=&#34;1240px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11.png&#34;
	width=&#34;1698&#34;
	height=&#34;358&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;474&#34;
		data-flex-basis=&#34;1138px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12.png&#34;
	width=&#34;1704&#34;
	height=&#34;368&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;463&#34;
		data-flex-basis=&#34;1111px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;
&lt;h3 id=&#34;when-pre-training-might-help&#34;&gt;When pre-training might help?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Related &lt;strong&gt;supervised&lt;/strong&gt; pre-training dataset. But not always feasible.&lt;/li&gt;
&lt;li&gt;If the rich features are absent.&lt;/li&gt;
&lt;li&gt;If the downstream split distributions are substantially different.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;when-the-gain-dimishes&#34;&gt;When the gain dimishes?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;If using rich features.&lt;/li&gt;
&lt;li&gt;If don’t have the highly relevant supervisions.&lt;/li&gt;
&lt;li&gt;If the downstream split is balanced.&lt;/li&gt;
&lt;li&gt;If the self-supervised learning dataset lacks diversity.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;why-pre-training-may-not-help-in-some-cases&#34;&gt;Why pre-training may not help in some cases?&lt;/h3&gt;
&lt;p&gt;Some of the pre-training methods (e.g. node label prediction) might be too easy&lt;br&gt;
→ Transfer less knowledge.&lt;/p&gt;
&lt;p&gt;So…&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use rich features&lt;/li&gt;
&lt;li&gt;Use balanced scaffold&lt;/li&gt;
&lt;li&gt;Use related supervised pre-training dataset&lt;/li&gt;
&lt;li&gt;Use difficult pre-training task (for self-supervised pre-training) and use high-quality negative samples.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Graph Self-supervised Learning with Accurate Discrepancy Learning</title>
        <link>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</link>
        <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/0.png" alt="Featured image of post Graph Self-supervised Learning with Accurate Discrepancy Learning" /&gt;&lt;p&gt;NeurIPS, &amp;lsquo;22,&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=SgZ-glWWUlq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://openreview.net/forum?id=SgZ-glWWUlq&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Authors proposed a framework called D-SLA that aims to learn the exact discrepancy between the original and the perturbed graphs.&lt;/li&gt;
&lt;li&gt;Three major components
&lt;ol&gt;
&lt;li&gt;Learn to distinguish whether each graph is the original graph or the perturbed one.&lt;/li&gt;
&lt;li&gt;Capture the amount of discrepancy for each perturbed graph (using edit distance)&lt;/li&gt;
&lt;li&gt;Learn relative discrepancy with other graphs&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;h3 id=&#34;graph-neural-networks-gnn&#34;&gt;Graph Neural Networks (GNN)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Aggregate the features from its neighbors&lt;/li&gt;
&lt;li&gt;Combining the aggregated message&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variants of Update &amp;amp; Aggregate functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Graph Convolution Network (GCN)&lt;/p&gt;
&lt;p&gt;General convolution operation + Mean aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GraphSAGE&lt;/p&gt;
&lt;p&gt;Concatenate representations of neighbors with its own representation when updating&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Attention Network (GAT)&lt;/p&gt;
&lt;p&gt;Considers the relative importance among neighboring nodes when aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Isomorphism Network (GIN)&lt;/p&gt;
&lt;p&gt;Sum aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;self-supervised-learning-for-graphs-gsl&#34;&gt;Self-supervised learning for graphs (GSL)&lt;/h3&gt;
&lt;p&gt;Aims to learn a good representation of the graphs in an unsupervised manner.&lt;/p&gt;
&lt;p&gt;→ Transfer this knowledge to downstream tasks.&lt;/p&gt;
&lt;p&gt;Most prevalent framework for GSL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Predictive learning (PL)&lt;/p&gt;
&lt;p&gt;Aims to learn &lt;strong&gt;contextual relationships&lt;/strong&gt; by predicting sub-graphical features (nodes, edges, subgraphs)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;predict the attributes of masked nodes&lt;/li&gt;
&lt;li&gt;predict the presence of an edge or a path&lt;/li&gt;
&lt;li&gt;predict the generative sequence, contextual property, and motifs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But predictive learning &lt;strong&gt;may not capture the global structures and/or semantics of graphs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled.png&#34;
	width=&#34;896&#34;
	height=&#34;520&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrastive learning (CL)&lt;/p&gt;
&lt;p&gt;Aims to &lt;strong&gt;capture global level information.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Early CL learn the similarity between the entire graph and its substructure.&lt;/li&gt;
&lt;li&gt;Others include attribute masking, edge perturbation, and subgraph sampling.&lt;/li&gt;
&lt;li&gt;Recent CL adversarial methods generate positive examples either by adaptively removing the edges or by adjusting the attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But CL &lt;strong&gt;may not distinguish two topologically similar graphs yet having completely different properties.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1.png&#34;
	width=&#34;894&#34;
	height=&#34;526&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2.png&#34;
	width=&#34;946&#34;
	height=&#34;384&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Minimize $\mathcal{L}_{CL} = - \log \frac{f_{\text{sim}} (h_{\mathcal{G}_i}, h_{\mathcal{G}_j})}{\sum_{\mathcal{G}&amp;rsquo;, \mathcal{G&amp;rsquo; \neq \mathcal{G}_0}}f_{\text{sim}}(h_{\mathcal{G}_i}, h_{\mathcal{G}&amp;rsquo;})}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{G}_0$: original graph&lt;/li&gt;
&lt;li&gt;$\mathcal{G}_i, \mathcal{G}_j$: perturbed graphs&lt;/li&gt;
&lt;li&gt;$\mathcal{G}&amp;rsquo;$: other graph in the same batch with the $\mathcal{G}_0$, a.k.a. negative graph&lt;/li&gt;
&lt;li&gt;positive pair: $(\mathcal{G}_i, \mathcal{G}_j)$; negative pair: $(\mathcal{G}_i, \mathcal{G}&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;$f_\text{sim}$: similarity function between two graphs → $L_2$ distance or cosine similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→ similarity of positive pair $\uparrow$, similarity of negative pair $\downarrow$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;discrepancy-learning&#34;&gt;Discrepancy Learning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3.png&#34;
	width=&#34;1312&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;326&#34;
		data-flex-basis=&#34;783px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Discriminate original vs perturbed&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perturbed graph could be semantically incorrect!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;→ Embed perturbed graph apart from original.&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{GD} = - \log \Big (\frac{e^{S_0}}{e^{S_0} + \sum_{i \geq 1}e^{S_i}} \Big ) \text{ with } S = f_S(h_{\mathcal{G}})$&lt;/p&gt;
&lt;p&gt;Intuitively,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;large value of $e^{S_0}$ for the original graph&lt;/li&gt;
&lt;li&gt;small value of $e^{S_i}$ for the perturbed graphs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How to perturb?&lt;/p&gt;
&lt;p&gt;Aim at perturbed graph to be semantically incorrect&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Remove or add a small number of edges&lt;/p&gt;
&lt;p&gt;Manipulate the edge set by removing existing edges  + adding new edges on $\mathcal{X}_\mathcal{E}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mask node attributes&lt;/p&gt;
&lt;p&gt;Randomly mask the node attributes on $\mathcal{X}_\mathcal{V}$ for both original and perturbed graphs&lt;/p&gt;
&lt;p&gt;(to make it more difficult to distinguish between them)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\mathcal{G}_0 = (\mathcal{V}, \mathcal{E}, \tilde{\mathcal{X}^0_{\mathcal{V}}}, \mathcal{X}_{\mathcal{E}}), \tilde{\mathcal{X}^0_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;$\mathcal{G}_i = (\mathcal{V}, \mathcal{E}^i, \tilde{\mathcal{X}^i_{\mathcal{V}}}, \mathcal{X}^i_{\mathcal{E}}), \tilde{\mathcal{X}^i_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G}), (\mathcal{E}^i, \mathcal{X}^i_{\mathcal{E}}) \sim \texttt{P}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;Personal opinion&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The real usage of discriminator loss will be to push original &amp;amp; perturbed graph apart, while applying edit distance loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discrepancy with Edit distance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How dissimilar?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Usually, we need to measure the graph distance, such as edit distance.&lt;/p&gt;
&lt;p&gt;Edit distance: number of insertion, deletion, and substitution operations for nodes &amp;amp; edges to transform one graph from another. → NP hard!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But we know the exact number of perturbations for each graphs&lt;/p&gt;
&lt;p&gt;→ use it as distance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\mathcal{L}_{edit} = \sum_{i, j} \Big ( \frac{d_i}{e_i} - \frac{d_j}{e_j}\Big )^2 \text{ with } d_i = f_{\text{diff}}(h_{\mathcal{G}_0}, h_{\mathcal{G}_i})$&lt;/p&gt;
&lt;p&gt;$f_{\text{diff}}$ measures the embedding level differences between graphs with &lt;code&gt;L2 norm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;$e_i$: edit distance (number of perturbations)&lt;/p&gt;
&lt;p&gt;The trivial solution for the edit distance loss is $d_i = d_j = 0$. But because of the discriminator loss, this is not possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relative discrepancy learning with other graphs&lt;/p&gt;
&lt;p&gt;Assumption:&lt;/p&gt;
&lt;p&gt;Distance between original and negative graphs in the same batch is larger than the distance between the original and perturbed graphs with some amount of margin.&lt;/p&gt;
&lt;p&gt;Formally,&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{margin} = \sum_{i, j} \max (0, \alpha + d_i - d&amp;rsquo;_j)$&lt;/p&gt;
&lt;p&gt;$d_i$: distance between original and its perturbed graphs&lt;/p&gt;
&lt;p&gt;$d&amp;rsquo;_j$: distance between original and negative graphs&lt;/p&gt;
&lt;p&gt;Intuitively, $\alpha + d_i &amp;lt; d&amp;rsquo;_j$ !&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;overall-loss&#34;&gt;Overall loss&lt;/h3&gt;
&lt;p&gt;$\mathcal{L} = \mathcal{L}_{GD} + \lambda_1 \mathcal{L}_{edit} + \lambda_2 \mathcal{L}_{margin}$&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4.png&#34;
	width=&#34;2760&#34;
	height=&#34;878&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;314&#34;
		data-flex-basis=&#34;754px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5.png&#34;
	width=&#34;662&#34;
	height=&#34;656&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6.png&#34;
	width=&#34;2072&#34;
	height=&#34;640&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;777px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>PhysChem: Deep Molecular Representation Learning via Fusing Physical and Chemical Information</title>
        <link>https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/</link>
        <pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1.png" alt="Featured image of post PhysChem: Deep Molecular Representation Learning via Fusing Physical and Chemical Information" /&gt;&lt;p&gt;NeurIPS Poster, &amp;lsquo;21,&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2112.04624&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/abs/2112.04624&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Used physicist network (PhysNet) and chemist network (ChemNet) simultaneously, and each network shares information to solve individual tasks.&lt;/li&gt;
&lt;li&gt;PhysNet: Neural physical engine. Mimics molecular dynamics to predict conformation.&lt;/li&gt;
&lt;li&gt;ChemNet: Message passing network for chemical &amp;amp; biomedical property prediction.&lt;/li&gt;
&lt;li&gt;Molecule without 3D conformation can be inferred during test time.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Molecular representation learning:&lt;br&gt;
Embedding molecules into latent space for downstream tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Physical Engines&lt;br&gt;
Neural networks are capable of learning annotated potentials and forces in particle systems.&lt;br&gt;
HamNet proposed a neural physical engine that operated on a generalized space, where positions and momentums of atoms were defined as high-dimensional vectors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-task learning&lt;br&gt;
Sharing representations for different but related tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model fusion&lt;br&gt;
Merging different models on identical tasks to improve performance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;notation&#34;&gt;Notation&lt;/h2&gt;
&lt;p&gt;Graph $\mathcal{M} = (\mathcal{V}, \mathcal{E}, n, m, \mathbf{X}^v, \mathbf{X}^e)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{V}$: set of $n$ atoms&lt;/li&gt;
&lt;li&gt;$\mathcal{E}$: set of $m$ chemical bonds&lt;/li&gt;
&lt;li&gt;$\mathbf{X}^v \in \mathbb{R}^{n \times d_v} = (x^v_1, &amp;hellip;, x^v_n)^\top$: matrix of atomic features&lt;/li&gt;
&lt;li&gt;$\mathbf{X}^e \in \mathbb{R}^{m \times d_e} = (x^e_1, &amp;hellip;, x^e_m)^\top$: matrix of bond features&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1.png&#34;
	width=&#34;2000&#34;
	height=&#34;709&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1_hu614a3ffe516a8cd557a8bbd359513341_952945_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1_hu614a3ffe516a8cd557a8bbd359513341_952945_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;282&#34;
		data-flex-basis=&#34;677px&#34;
	
&gt;
Figure 1. PhysChem Architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Initializer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input: atomic features, bond features (from RDKit)&lt;/li&gt;
&lt;li&gt;Layer: fully connected layers&lt;/li&gt;
&lt;li&gt;Output:&lt;/li&gt;
&lt;li&gt;bond states, atom states for ChemNet&lt;br&gt;
$v^{(0)}_i = \text{FC}(x^v_i), i\in \mathcal{V}$&lt;br&gt;
$e^{(0)}_{i,j} = \text{FC}(x^e_{i,j}), (i, j)\in \mathcal{E}$&lt;/li&gt;
&lt;li&gt;atom positions, atomic momenta for PhysNet&lt;br&gt;
Bond strength adjacency matrix&lt;br&gt;
$$A(i,j)=\begin{cases}0, &amp;amp; \text{if $(i,j) \notin \mathcal{E}$} \\ \text{FC}_{\text{sigmoid}}(x^e_{i,j}), &amp;amp; \text{if $(i,j) \in \mathcal{E}$} \end{cases}$$
$\tilde{V} = \text{GCN}(A, V^{(0)})$&lt;br&gt;
${ (q^{(0)}_i \oplus p^{(0)}_i)}  = \text{LSTM}({\tilde{v}_i}), i \in \mathcal{V}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PhysNet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PhysNet is inspired by &lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=q-cnWaaoUTH&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HamNet&lt;/a&gt;.&lt;br&gt;
HamNet showed that neural networks can simulate molecular dynamics for conformation prediction.&lt;/li&gt;
&lt;li&gt;Directly parameterize the forces between each pair of atoms.&lt;/li&gt;
&lt;li&gt;Consider the effects of chemical interactions(e.g. bond types) by cooperating with ChemNet’s bond states.&lt;/li&gt;
&lt;li&gt;Introduces torsion forces.&lt;/li&gt;
&lt;li&gt;Output: 3D conformation
&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet.jpeg&#34;
	width=&#34;1424&#34;
	height=&#34;1000&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet_huc04268559fc6ac467b55debd1d11cbcb_463344_480x0_resize_q75_box.jpeg 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet_huc04268559fc6ac467b55debd1d11cbcb_463344_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChemNet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ChemNet modifies MPNN(message passing neural network) for molecular representation learning.&lt;/li&gt;
&lt;li&gt;Output: Molecule representation
&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet.jpeg&#34;
	width=&#34;1598&#34;
	height=&#34;1000&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet_huea3837eddd924d917074e41bba2e849a_561970_480x0_resize_q75_box.jpeg 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet_huea3837eddd924d917074e41bba2e849a_561970_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;loss&#34;&gt;Loss&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$L_{\text{phys}}$: Conn-k loss for Conformation prediction (PhysNet)&lt;/p&gt;
&lt;p&gt;$k$-hop connectivity loss&lt;/p&gt;
&lt;p&gt;$L_{\text{Conn}-k}(\hat{\mathbf{R}}, \mathbf{R}) = |\frac{1}{n} \hat{\mathbf{C}}^{(k)} \odot (\hat{\mathbf{D}} - \mathbf{D}) \odot (\hat{\mathbf{D}} - \mathbf{D}) |_{F}$&lt;/p&gt;
&lt;p&gt;$\odot$: element-wise product&lt;/p&gt;
&lt;p&gt;$| \cdot |$: Frobenius norm&lt;/p&gt;
&lt;p&gt;$(\hat{\mathbf{D}} - \mathbf{D})$ : distance matrix of the real and predicted conformations $(\hat{\mathbf{R}} - \mathbf{R})$&lt;/p&gt;
&lt;p&gt;$\hat{\mathbf{C}}^{(k)}$: normalized $k$-hop connectivity matrix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$L_{\text{chem}}$: MAE or Cross entropy loss for Property prediction (ChemNet)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Total loss&lt;/p&gt;
&lt;p&gt;$L_{\text{total}} = \lambda L_{\text{phys}} + L_{\text{chem}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Checkpoints&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Is Conn-k loss generally used in other conformation prediction models?&lt;/p&gt;
&lt;p&gt;No! But seems related to local distance loss.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is triplet descriptor generally used in other models?&lt;/p&gt;
&lt;p&gt;No!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MAML: Model-Agnostic Meta -Learning for Fast Adaptation of Deep Networks</title>
        <link>https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/</link>
        <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/</guid>
        <description>&lt;img src="https://gujh14.github.io/thumbnail.png" alt="Featured image of post MAML: Model-Agnostic Meta -Learning for Fast Adaptation of Deep Networks" /&gt;&lt;p&gt;ICML, &amp;lsquo;17&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1703.03400&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;MAML is a general and model-agnostic algorithm that can be directly applied to a model trained with &lt;strong&gt;gradient descent&lt;/strong&gt; procedure.&lt;/li&gt;
&lt;li&gt;MAML does not expand the number of learned parameters.&lt;/li&gt;
&lt;li&gt;MAML does not place constraints on the model architecture.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;keywords&#34;&gt;Keywords&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Model agnostic&lt;/li&gt;
&lt;li&gt;Fast adaptation&lt;/li&gt;
&lt;li&gt;Optimization based approach&lt;/li&gt;
&lt;li&gt;Learning good model parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Common Approaches of Meta-Learning and MAML&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled.png&#34;
	width=&#34;1522&#34;
	height=&#34;726&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled_hu2810079d992af17206a7c032e637187e_371302_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled_hu2810079d992af17206a7c032e637187e_371302_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;MAML is one of the most influential model of optimization-based approaches.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled1.png&#34;
	width=&#34;1484&#34;
	height=&#34;834&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled1_hu7ef081ff7698cafbf43593ac8d1bcbcd_922101_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled1_hu7ef081ff7698cafbf43593ac8d1bcbcd_922101_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;https://youtu.be/Izqod36syY8&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;427px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A few terminologies of meta-learning problems&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled2.png&#34;
	width=&#34;2102&#34;
	height=&#34;1524&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled2_hu73d9cc73c6ab2d7d1dd2a961a777268b_357680_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled2_hu73d9cc73c6ab2d7d1dd2a961a777268b_357680_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;https://ai.stanford.edu/~cbfinn/_files/dissertation.pdf&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;331px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled3.png&#34;
	width=&#34;636&#34;
	height=&#34;382&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled3_hu49418efd97bf156417160555a8d5baef_47140_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled3_hu49418efd97bf156417160555a8d5baef_47140_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;399px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Goal of ideal artificial agent:&lt;/p&gt;
&lt;p&gt;Learning and adapting quickly from only a few examples.&lt;/p&gt;
&lt;p&gt;To do so, an agent must..&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrate its prior experience with a small amount of new information.&lt;/li&gt;
&lt;li&gt;Avoid overfitting to the new data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→ Meta-learning has same goals.&lt;/p&gt;
&lt;p&gt;MAML:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The key idea of MAML is to train the model&amp;rsquo;s &lt;strong&gt;initial parameters&lt;/strong&gt; such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Learning process of MAML:&lt;/p&gt;
&lt;p&gt;MAML maximizes the sensitivity of the loss functions of new tasks.&lt;/p&gt;
&lt;p&gt;Authors demonstrated the algorithm on three different model types.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Few-shot regression&lt;/li&gt;
&lt;li&gt;Image classification&lt;/li&gt;
&lt;li&gt;Reinforcement learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-model-agnostic-meta-learning&#34;&gt;2. Model-Agnostic Meta Learning&lt;/h2&gt;
&lt;h3 id=&#34;21-meta-learning-problem-set-up&#34;&gt;2.1. Meta-Learning Problem Set-Up&lt;/h3&gt;
&lt;p&gt;To apply MAML to a variety of learning problems, authors introduce a generic notion of a learning task:&lt;/p&gt;
&lt;p&gt;$\mathcal{T} = { \mathcal{L}(\mathbf{x}_1, \mathbf{a}_1, &amp;hellip;, \mathbf{x}_H, \mathbf{a}_H), q(\mathbf{x}_1), q(\mathbf{x}_{t+1}|\mathbf{x}_t, \mathbf{a}_t), H }$&lt;/p&gt;
&lt;p&gt;Each task $\mathcal{T}$ consists of..&lt;/p&gt;
&lt;p&gt;$\mathcal{L}$: a loss function, might be misclassification loss or a cost function in a Markov decision process&lt;/p&gt;
&lt;p&gt;$q(\mathbf{x}_1)$: a distribution over initial observations&lt;/p&gt;
&lt;p&gt;$q(\mathbf{x}_{t+1}|\mathbf{x}_t , \mathbf{a}_t)$: a transition distribution&lt;/p&gt;
&lt;p&gt;$H$: an episode length(e.g. in i.i.d. supervised learning problems, the length $H = 1$.)&lt;/p&gt;
&lt;p&gt;Authors consider a distribution over tasks $p(\mathcal{T})$&lt;/p&gt;
&lt;p&gt;Meta-training:&lt;/p&gt;
&lt;p&gt;A new task $\mathcal{T}_i$ is sampled from $p(\mathcal{T})$.&lt;/p&gt;
&lt;p&gt;The model is trained with only $K$ samples drawn from $q_i$.&lt;/p&gt;
&lt;p&gt;Loss $\mathcal{L}_{\mathcal{T}_i}$ is calculated and feedbacked to model.&lt;/p&gt;
&lt;p&gt;Model $f$ is tested on new samples from $\mathcal{T}_i$.&lt;/p&gt;
&lt;p&gt;The model $f$ is then improved by considering how the $test$ error on new data from $q_i$ changes with respect to the parameters.&lt;/p&gt;
&lt;h3 id=&#34;22-a-model-agnostic-meta-learning-algorithm&#34;&gt;2.2. A Model-Agnostic Meta-Learning Algorithm&lt;/h3&gt;
&lt;p&gt;Intuition: Some internal representations are more transferrable than others. How can we encourage the emergence of such general-purpose representations?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled4.png&#34;
	width=&#34;2354&#34;
	height=&#34;1132&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled4_huffde7ac579bb4dc3080f2015f65a7fd2_1156243_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled4_huffde7ac579bb4dc3080f2015f65a7fd2_1156243_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;499px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled5.png&#34;
	width=&#34;2360&#34;
	height=&#34;1116&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled5_hu896a6c8d932c96e0c863feb29ee4c599_1114541_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled5_hu896a6c8d932c96e0c863feb29ee4c599_1114541_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;507px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A model $f_\theta$ has paramters $\theta$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For each task $\mathcal{T}_i$, $f_\theta$&amp;rsquo;s parameters $\theta$ become $\theta_i&amp;rsquo;$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Algorithm&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled6.png&#34;
	width=&#34;862&#34;
	height=&#34;598&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled6_hu4f3fbc659182e4f29d6ca5f28e4663c9_286070_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled6_hu4f3fbc659182e4f29d6ca5f28e4663c9_286070_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;345px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cf) Terminologies for below description(temporarily defined by JH Gu)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled7.png&#34;
	width=&#34;1708&#34;
	height=&#34;1352&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled7_hu8110c6352be8c0d888d6667531616c11_282586_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled7_hu8110c6352be8c0d888d6667531616c11_282586_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;303px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Divide tasks&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Separate tasks into meta-training task set(${\mathcal{T}_i^{\text{tr}}}$) and meta-test task set(${\mathcal{T}_i^{\text{test}}}$).&lt;/p&gt;
&lt;p&gt;(We can think of ${\mathcal{T}_i^{\text{tr}}}$ as monthly tests(모의고사), and ${\mathcal{T}_i^{\text{test}}}$ as annual tests(수능))&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For each task, divide each samples into $\mathcal{D}_{\mathcal{T}_i}^{\text{study}}$(task-specific samples for studying, also called as support set), $\mathcal{D}_{\mathcal{T_i}}^{\text{check}}$(task-specific samples for checking, also called as query set)&lt;/p&gt;
&lt;p&gt;(We can think of $\mathcal{D}_{\mathcal{T}_i}^{\text{study}}$ as 필수예제 in 수학의 정석, and $\mathcal{D}_{\mathcal{T}_i}^{\text{check}}$ as 연습문제 in 수학의 정석)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Meta-training using meta-training task set ${\mathcal{T}_i^{\text{tr}}}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Inner loop(task-specific $K$-shot learning)&lt;/p&gt;
&lt;p&gt;For each $\mathcal{T}_i$ in ${\mathcal{T}_i^{\text{tr}}}$, a new parameter $\theta_i&amp;rsquo;$ is created.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Each $\theta_i&amp;rsquo;$ is initialized as $\theta$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With task-specific samples for studying($\mathcal{D}_{\mathcal{T}_i^{\text{tr}}}^{\text{study}}$), each $\theta_i&amp;rsquo;$ is updated by:&lt;/p&gt;
&lt;p&gt;$$
\theta_i&amp;rsquo; = \theta - \alpha \nabla_\theta \mathcal{L}_{\mathcal{T}_i}(f_\theta)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Outer loop(meta-learning across tasks)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;With task-specific samples for checking($\mathcal{D}_{\mathcal{T_i}^{\text{tr}}}^{\text{check}}$), $\theta$ is updated by:&lt;/p&gt;
&lt;p&gt;$$
\theta = \theta - \beta \nabla_\theta \sum_{\mathcal{T}_i \sim p(\mathcal{T})}\mathcal{L}_{\mathcal{T}_i} (f_{\theta_i&amp;rsquo;})
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cf) second-order derivative(Hessian) problem&lt;/p&gt;
&lt;p&gt;The MAML meta-gradient update(outer loop) involves a gradient through a gradient, which can be resource-intensive. This requires an additional backward pass through $f$ to compute Hessian vector products.&lt;/p&gt;
&lt;p&gt;$$
\begin{align*} \textcolor{red}{\theta&amp;rsquo;} &amp;amp;= \theta - \alpha \nabla_\theta \mathcal{L}(\theta) \ \nabla_\theta \mathcal{L}(\textcolor{red}{\theta&amp;rsquo;}) &amp;amp;= (\textcolor{red}\nabla_{\textcolor{red}{\theta&amp;rsquo;}} \mathcal{L}(\textcolor{red}{\theta&amp;rsquo;})) \cdot (\nabla_\theta \textcolor{red}{\theta&amp;rsquo;}) \ &amp;amp;= (\textcolor{red}\nabla_{\textcolor{red}{\theta&amp;rsquo;}} \mathcal{L}(\textcolor{red}{\theta&amp;rsquo;})) \cdot (\nabla_\theta (\theta - \alpha \nabla_\theta \mathcal{L}(\theta)) \ &amp;amp;\approx (\textcolor{red}\nabla_{\textcolor{red}{\theta&amp;rsquo;}} \mathcal{L}(\textcolor{red}{\theta&amp;rsquo;})) \cdot (\nabla_\theta \theta) \ &amp;amp;= (\textcolor{red}\nabla_{\textcolor{red}{\theta&amp;rsquo;}} \mathcal{L}(\textcolor{red}{\theta&amp;rsquo;})) \end{align*}
$$&lt;/p&gt;
&lt;p&gt;Authors included a comparison to drop the backward pass term and using just the first-order approximation, which showed not much difference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled8.png&#34;
	width=&#34;1174&#34;
	height=&#34;308&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled8_hu06f5aec29bc68380b99667335eb21667_106124_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled8_hu06f5aec29bc68380b99667335eb21667_106124_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;381&#34;
		data-flex-basis=&#34;914px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Measure model performance using meta-test task set ${\mathcal{T}_i^{\text{test}}}$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For each $\mathcal{T}_i$ in ${\mathcal{T}_i^{\text{test}}}$, adjust task-specific parameters with $\mathcal{D}_{\mathcal{T}_i^{\text{test}}}^{\text{study}}$.&lt;/li&gt;
&lt;li&gt;Test the performance with $\mathcal{D}_{\mathcal{T_i}^{\text{test}}}^{\text{check}}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-species-of-maml&#34;&gt;3. Species of MAML&lt;/h2&gt;
&lt;h3 id=&#34;31-supervised-regression-and-classification&#34;&gt;3.1. Supervised Regression and Classification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Algorithm&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled9.png&#34;
	width=&#34;858&#34;
	height=&#34;700&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled9_hu8161162bc48d5bed870c55b7080befad_351296_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled9_hu8161162bc48d5bed870c55b7080befad_351296_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;294px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Formalizing supervised regression and classification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Horizon $H = 1$&lt;/li&gt;
&lt;li&gt;Drop the timestep subscript on $\mathbf{x}_t$ (since model accepts a single input and produces a single output)&lt;/li&gt;
&lt;li&gt;The task $\mathcal{T}_i$ generates $K$ i.i.d. observations $\mathbf{x}$ from $q_i$&lt;/li&gt;
&lt;li&gt;Task loss is represented by the error between the model&amp;rsquo;s output for $\mathbf{x}$ and the corresponding target values $\mathbf{y}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Loss functions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;MSE for regression&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}_{\mathcal{T}_i}(f_\phi) = \sum_{\mathbf{x}^{(j)}, \mathbf{y}^{(j)} \sim \mathcal{T}_i} | f_\phi(\mathbf{x}^{(j)}) - \mathbf{y}^{(j)}|^2_2
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cross entropy loss for discrete classification&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}_{\mathcal{T}_i}(f_\phi) = \sum_{\mathbf{x}^{(j)}, \mathbf{y}^{(j)} \sim \mathcal{T}_i} \big\{ \mathbf{y}^{(j)} \log f_\phi (\mathbf{x}^{(j)}) - (1-\mathbf{y}^{(j)})\log(1-f_\phi(\mathbf{x}^{(j)}) \big\}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-reinforcement-learning&#34;&gt;3.2. Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Algorithm&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled10.png&#34;
	width=&#34;858&#34;
	height=&#34;698&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled10_hu3c6285d700509d496607cdcdbd973580_136262_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled10_hu3c6285d700509d496607cdcdbd973580_136262_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Untitled&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;295px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Goal of MAML in RL:&lt;/p&gt;
&lt;p&gt;Quickly acquire a policy for a new test task using only a small amount of experience in the test setting.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Formalizing RL&lt;/p&gt;
&lt;p&gt;Each RL task $\mathcal{T}_i$ contains..&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial state distribution $q_i(\mathbf{x}_1)$&lt;/li&gt;
&lt;li&gt;Transition distribution $q_i(\mathbf{x}_{t+1}|\mathbf{x}_t, \mathbf{a}_t)$
&lt;ul&gt;
&lt;li&gt;$\mathbf{a}_t$: action&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Loss $\mathcal{L}_{\mathcal{T}_i}$, which corresponds to the negative reward function $R$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore, entire task is a Markov decision process(MDP) with horizon $H$&lt;/p&gt;
&lt;p&gt;The model being learned, $f_\theta$, is a policy that maps from states $\mathbf{x}_t$ to a distribution over actions $\mathbf{a}_t$ at each timestep $t \in { 1, &amp;hellip;, H}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Loss function for task $\mathcal{T}_i$ and model $f_\phi$:&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}_{\mathcal{T}_i}(f_\phi) = -\mathbb{E}_{\mathbf{x}_t, \mathbf{a}_t \sim f_\phi, q_{\mathcal{T}_i}} \bigg [ \sum_{t=1}^H R_i(\mathbf{x}_t, \mathbf{a}_t) \bigg ]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Policy gradient method&lt;/p&gt;
&lt;p&gt;Since the expected reward is generally not differentiable due to unknown dynamics, authors used policy gradient methods to estimate the gradient.&lt;/p&gt;
&lt;p&gt;The policy gradient method is an on-policy algorithm&lt;/p&gt;
&lt;p&gt;→ There are additional sampling procedures in step 5 and 8.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-comparison-with-related-works&#34;&gt;4. Comparison with related works&lt;/h2&gt;
&lt;p&gt;Comparison with other popular approaches&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Training a meta-learner that learns how to update the parameters of the learner&amp;rsquo;s model&lt;/p&gt;
&lt;p&gt;ex) On the optimization of a synaptic learning rule(Bengio et al. 1992)&lt;/p&gt;
&lt;p&gt;→ Requires additional parameters, while MAML does not.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training to compare new examples in a learned metric space&lt;/p&gt;
&lt;p&gt;ex) Siamese networks(Koch, 2015), recurrence with attention mechanisms(Vinyals et al. 2016)&lt;/p&gt;
&lt;p&gt;→ Difficult to directly extend to our problems, such as reinforcement learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training memory-augmented models&lt;/p&gt;
&lt;p&gt;ex) Meta-learning with memory-augmented neural networks(Santoro et al. 2016)&lt;/p&gt;
&lt;p&gt;The recurrent learner is trained to adapt to new tasks as it is rolled out.&lt;/p&gt;
&lt;p&gt;→ Not really straightforward.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-experimental-evaluation&#34;&gt;5. Experimental Evaluation&lt;/h2&gt;
&lt;p&gt;Three questions&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Can MAML enable fast learning of new tasks?&lt;/li&gt;
&lt;li&gt;Can MAML be used for meta-learning in multiple different domains?&lt;/li&gt;
&lt;li&gt;Can a model learned with MAML continue to improve with additional gradient updates and/or examples?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;51-regression&#34;&gt;5.1. Regression&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled11.png&#34;
	width=&#34;2054&#34;
	height=&#34;640&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled11_hueb5d57f33093f3e6c97de66eea7eedea_389010_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled11_hueb5d57f33093f3e6c97de66eea7eedea_389010_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;320&#34;
		data-flex-basis=&#34;770px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled12.png&#34;
	width=&#34;2034&#34;
	height=&#34;650&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled12_hu1ff3a227b90faeda4e52f0040b735e3e_305489_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled12_hu1ff3a227b90faeda4e52f0040b735e3e_305489_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;312&#34;
		data-flex-basis=&#34;751px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;52-classification&#34;&gt;5.2. Classification&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled13.png&#34;
	width=&#34;1796&#34;
	height=&#34;808&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled13_hu8b2f95fd4f45de82cd6351f281788721_270027_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled13_hu8b2f95fd4f45de82cd6351f281788721_270027_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;533px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled14.png&#34;
	width=&#34;2042&#34;
	height=&#34;246&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled14_hubf35b4892da9571cbc8a38fed428c704_107171_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled14_hubf35b4892da9571cbc8a38fed428c704_107171_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;830&#34;
		data-flex-basis=&#34;1992px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;53-reinforcement-learning&#34;&gt;5.3. Reinforcement Learning&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled15.png&#34;
	width=&#34;1002&#34;
	height=&#34;734&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled15_hucc6319bab99c944b90e93c405f346352_263853_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled15_hucc6319bab99c944b90e93c405f346352_263853_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled16.png&#34;
	width=&#34;2042&#34;
	height=&#34;576&#34;
	srcset=&#34;https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled16_hu9fd7b30672c4ee6f028386c6c663c852_404417_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/maml-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/Untitled16_hu9fd7b30672c4ee6f028386c6c663c852_404417_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;354&#34;
		data-flex-basis=&#34;850px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://youtu.be/Izqod36syY8&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;KAIST NeuroAI JC_#1 Meta Learning (편집본)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ai.stanford.edu/~cbfinn/_files/dissertation.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ai.stanford.edu/~cbfinn/_files/dissertation.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://velog.io/@tobigs_xai/10%ec%a3%bc%ec%b0%a8-MAML-Model-agnostic-Meta-Learning-for-Fast-Adaptation-of-Deep-Networks-%eb%85%bc%eb%ac%b8-%eb%a6%ac%eb%b7%b0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[10주차] (MAML) Model-agnostic Meta Learning for Fast Adaptation of Deep Networks 논문 리뷰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Meta-Learning: Learning to Learn Fast&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
