<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Molecule on JH Gu&#39;s Tech Blog</title>
        <link>https://gujh14.github.io/tags/molecule/</link>
        <description>Recent content in Molecule on JH Gu&#39;s Tech Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 01 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://gujh14.github.io/tags/molecule/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Useful Resources for Molecule Learning (in Progress)</title>
        <link>https://gujh14.github.io/p/useful-resources-for-molecule-learning-in-progress/</link>
        <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/useful-resources-for-molecule-learning-in-progress/</guid>
        <description>&lt;h2 id=&#34;m2d2&#34;&gt;M2D2&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://m2d2.io/talks/m2d2/about/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;m2d2.io&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M2D2 is an abbreviation for Molecular Modeling &amp;amp; Drug Discovery. This is a community is co-organized by Valence Discovery and Mila - Quebec AI Institute.&lt;/li&gt;
&lt;li&gt;New presentation comes up every Tuesday via Zoom. Authors of recent papers introduce their work themselves and answers questions. Most of the sessions are recorded and uploaded on Youtube.&lt;/li&gt;
&lt;li&gt;Most papers have been accepted at top conferences.&lt;/li&gt;
&lt;li&gt;Highly recommend to watch those videos.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hugging-face&#34;&gt;Hugging Face&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/intro-graphml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface.co/blog/intro-graphml&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This blog article is a tutorial about machine learning techniques for Graphs.&lt;/li&gt;
&lt;li&gt;Blog is not tailor-made for molecules, but substantially introduced.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Does GNN Pre-training Help Molecular Representation?</title>
        <link>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</link>
        <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</guid>
        <description>&lt;p&gt;NeurIPS, &amp;lsquo;22&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2207.06010&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Does GNN Pre-training Help Molecular Representation?&lt;/a&gt;
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/thumbnail.png&#34;
	width=&#34;1816&#34;
	height=&#34;446&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/thumbnail_hube49b7519c97672414e9b0ddbe5479a4_229014_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/thumbnail_hube49b7519c97672414e9b0ddbe5479a4_229014_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;407&#34;
		data-flex-basis=&#34;977px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised pre-training alone &lt;strong&gt;does not&lt;/strong&gt; provide statistically significant improvements over non-pre-trained methods on downstream tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data splits, hand-crafted rich features, or hyperparameters&lt;/strong&gt; can bring significant improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled.png&#34;
	width=&#34;1722&#34;
	height=&#34;582&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;710px&#34;
	
&gt;
Pre-train objectives&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised
&lt;ul&gt;
&lt;li&gt;Node prediction&lt;/li&gt;
&lt;li&gt;Context prediction&lt;/li&gt;
&lt;li&gt;Motif prediction&lt;/li&gt;
&lt;li&gt;Contrastive learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supervised
&lt;ul&gt;
&lt;li&gt;Related tasks with label (e.g. ChEMBL dataset)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graph features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Basic
Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1905.12265&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hu et al.&lt;/a&gt;&lt;br&gt;
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled1.png&#34;
	width=&#34;1694&#34;
	height=&#34;508&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;333&#34;
		data-flex-basis=&#34;800px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich&lt;/p&gt;
&lt;p&gt;Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2007.02835&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rong et al.&lt;/a&gt; This is the superset of basic features.
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled2.png&#34;
	width=&#34;1338&#34;
	height=&#34;1076&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;124&#34;
		data-flex-basis=&#34;298px&#34;
	
&gt;
In downstream tasks, additional 2d normalized &lt;code&gt;rdNormalizedDescriptors&lt;/code&gt; are used (not in pre-training).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Downstream splits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Scaffold&lt;/p&gt;
&lt;p&gt;Sorts the molecule according to the scaffold, then partition the sorted list into train/valid/test splits. â†’ Deterministic&lt;/p&gt;
&lt;p&gt;Molecules of each set are most different ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Balanced scaffold&lt;/p&gt;
&lt;p&gt;Introduces the randomness in the sorting and splitting stages of Scaffold split.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GNN architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GIN&lt;/li&gt;
&lt;li&gt;GraphSAGE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pre-train dataset&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ZINC15 (self-supervised)&lt;/p&gt;
&lt;p&gt;2 million molecules. Pre-processed following Hu et al.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SAVI (self-supervised)&lt;/p&gt;
&lt;p&gt;1 billion drug-like molecules synthesized by computer simulated reactions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChEMBL (supervised)&lt;/p&gt;
&lt;p&gt;500k drugable molecules with 1,310 prediction target labels from bio-activity assays.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled3.png&#34;
	width=&#34;1696&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;421&#34;
		data-flex-basis=&#34;1012px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled4.png&#34;
	width=&#34;1694&#34;
	height=&#34;306&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;553&#34;
		data-flex-basis=&#34;1328px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled5.png&#34;
	width=&#34;1690&#34;
	height=&#34;390&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;433&#34;
		data-flex-basis=&#34;1040px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled6.png&#34;
	width=&#34;1712&#34;
	height=&#34;308&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled6_hu9e3333a7416211da0979291a20928457_104323_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled6_hu9e3333a7416211da0979291a20928457_104323_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;555&#34;
		data-flex-basis=&#34;1334px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled7.png&#34;
	width=&#34;1700&#34;
	height=&#34;326&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;521&#34;
		data-flex-basis=&#34;1251px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled8.png&#34;
	width=&#34;1702&#34;
	height=&#34;316&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;538&#34;
		data-flex-basis=&#34;1292px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled9.png&#34;
	width=&#34;1710&#34;
	height=&#34;324&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;527&#34;
		data-flex-basis=&#34;1266px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled10.png&#34;
	width=&#34;1696&#34;
	height=&#34;328&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;517&#34;
		data-flex-basis=&#34;1240px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled11.png&#34;
	width=&#34;1698&#34;
	height=&#34;358&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;474&#34;
		data-flex-basis=&#34;1138px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled12.png&#34;
	width=&#34;1704&#34;
	height=&#34;368&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/imgs/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;463&#34;
		data-flex-basis=&#34;1111px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;
&lt;h3 id=&#34;when-pre-training-might-help&#34;&gt;When pre-training might help?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Related &lt;strong&gt;supervised&lt;/strong&gt; pre-training dataset. But not always feasible.&lt;/li&gt;
&lt;li&gt;If the rich features are absent.&lt;/li&gt;
&lt;li&gt;If the downstream split distributions are substantially different.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;when-the-gain-dimishes&#34;&gt;When the gain dimishes?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;If using rich features.&lt;/li&gt;
&lt;li&gt;If donâ€™t have the highly relevant supervisions.&lt;/li&gt;
&lt;li&gt;If the downstream split is balanced.&lt;/li&gt;
&lt;li&gt;If the self-supervised learning dataset lacks diversity.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;why-pre-training-may-not-help-in-some-cases&#34;&gt;Why pre-training may not help in some cases?&lt;/h3&gt;
&lt;p&gt;Some of the pre-training methods (e.g. node label prediction) might be too easy&lt;br&gt;
â†’ Transfer less knowledge.&lt;/p&gt;
&lt;p&gt;Soâ€¦&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use rich features&lt;/li&gt;
&lt;li&gt;Use balanced scaffold&lt;/li&gt;
&lt;li&gt;Use related supervised pre-training dataset&lt;/li&gt;
&lt;li&gt;Use difficult pre-training task (for self-supervised pre-training) and use high-quality negative samples.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Graph Self-supervised Learning with Accurate Discrepancy Learning</title>
        <link>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</link>
        <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</guid>
        <description>&lt;p&gt;NeurIPS, &amp;lsquo;22,&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=SgZ-glWWUlq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Graph Self-supervised Learning with Accurate Discrepancy Learning&lt;/a&gt;
&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/thumbnail.png&#34;
	width=&#34;1414&#34;
	height=&#34;484&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/thumbnail_hu1da554d6c291b842a8ea287e9b40bdf6_233064_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/thumbnail_hu1da554d6c291b842a8ea287e9b40bdf6_233064_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;292&#34;
		data-flex-basis=&#34;701px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Authors proposed a framework called D-SLA that aims to learn the exact discrepancy between the original and the perturbed graphs.&lt;/li&gt;
&lt;li&gt;Three major components
&lt;ol&gt;
&lt;li&gt;Learn to distinguish whether each graph is the original graph or the perturbed one.&lt;/li&gt;
&lt;li&gt;Capture the amount of discrepancy for each perturbed graph (using edit distance)&lt;/li&gt;
&lt;li&gt;Learn relative discrepancy with other graphs&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;h3 id=&#34;graph-neural-networks-gnn&#34;&gt;Graph Neural Networks (GNN)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Aggregate the features from its neighbors&lt;/li&gt;
&lt;li&gt;Combining the aggregated message&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variants of Update &amp;amp; Aggregate functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Graph Convolution Network (GCN)&lt;/p&gt;
&lt;p&gt;General convolution operation + Mean aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GraphSAGE&lt;/p&gt;
&lt;p&gt;Concatenate representations of neighbors with its own representation when updating&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Attention Network (GAT)&lt;/p&gt;
&lt;p&gt;Considers the relative importance among neighboring nodes when aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Isomorphism Network (GIN)&lt;/p&gt;
&lt;p&gt;Sum aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;self-supervised-learning-for-graphs-gsl&#34;&gt;Self-supervised learning for graphs (GSL)&lt;/h3&gt;
&lt;p&gt;Aims to learn a good representation of the graphs in an unsupervised manner.&lt;/p&gt;
&lt;p&gt;â†’ Transfer this knowledge to downstream tasks.&lt;/p&gt;
&lt;p&gt;Most prevalent framework for GSL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Predictive learning (PL)&lt;/p&gt;
&lt;p&gt;Aims to learn &lt;strong&gt;contextual relationships&lt;/strong&gt; by predicting sub-graphical features (nodes, edges, subgraphs)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;predict the attributes of masked nodes&lt;/li&gt;
&lt;li&gt;predict the presence of an edge or a path&lt;/li&gt;
&lt;li&gt;predict the generative sequence, contextual property, and motifs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But predictive learning &lt;strong&gt;may not capture the global structures and/or semantics of graphs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled.png&#34;
	width=&#34;896&#34;
	height=&#34;520&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrastive learning (CL)&lt;/p&gt;
&lt;p&gt;Aims to &lt;strong&gt;capture global level information.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Early CL learn the similarity between the entire graph and its substructure.&lt;/li&gt;
&lt;li&gt;Others include attribute masking, edge perturbation, and subgraph sampling.&lt;/li&gt;
&lt;li&gt;Recent CL adversarial methods generate positive examples either by adaptively removing the edges or by adjusting the attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But CL &lt;strong&gt;may not distinguish two topologically similar graphs yet having completely different properties.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled1.png&#34;
	width=&#34;894&#34;
	height=&#34;526&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled2.png&#34;
	width=&#34;946&#34;
	height=&#34;384&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Minimize $\mathcal{L}_{CL} = - \log \frac{f_{\text{sim}} (h_{\mathcal{G}_i}, h_{\mathcal{G}_j})}{\sum_{\mathcal{G}&amp;rsquo;, \mathcal{G&amp;rsquo; \neq \mathcal{G}_0}}f_{\text{sim}}(h_{\mathcal{G}_i}, h_{\mathcal{G}&amp;rsquo;})}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{G}_0$: original graph&lt;/li&gt;
&lt;li&gt;$\mathcal{G}_i, \mathcal{G}_j$: perturbed graphs&lt;/li&gt;
&lt;li&gt;$\mathcal{G}&amp;rsquo;$: other graph in the same batch with the $\mathcal{G}_0$, a.k.a. negative graph&lt;/li&gt;
&lt;li&gt;positive pair: $(\mathcal{G}_i, \mathcal{G}_j)$; negative pair: $(\mathcal{G}_i, \mathcal{G}&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;$f_\text{sim}$: similarity function between two graphs â†’ $L_2$ distance or cosine similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â†’ similarity of positive pair $\uparrow$, similarity of negative pair $\downarrow$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;discrepancy-learning&#34;&gt;Discrepancy Learning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled3.png&#34;
	width=&#34;1312&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;326&#34;
		data-flex-basis=&#34;783px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Discriminate original vs perturbed&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perturbed graph could be semantically incorrect!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;â†’ Embed perturbed graph apart from original.&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{GD} = - \log \Big (\frac{e^{S_0}}{e^{S_0} + \sum_{i \geq 1}e^{S_i}} \Big ) \text{ with } S = f_S(h_{\mathcal{G}})$&lt;/p&gt;
&lt;p&gt;Intuitively,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;large value of $e^{S_0}$ for the original graph&lt;/li&gt;
&lt;li&gt;small value of $e^{S_i}$ for the perturbed graphs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How to perturb?&lt;/p&gt;
&lt;p&gt;Aim at perturbed graph to be semantically incorrect&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Remove or add a small number of edges&lt;/p&gt;
&lt;p&gt;Manipulate the edge set by removing existing edges  + adding new edges on $\mathcal{X}_\mathcal{E}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mask node attributes&lt;/p&gt;
&lt;p&gt;Randomly mask the node attributes on $\mathcal{X}_\mathcal{V}$ for both original and perturbed graphs&lt;/p&gt;
&lt;p&gt;(to make it more difficult to distinguish between them)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\mathcal{G}_0 = (\mathcal{V}, \mathcal{E}, \tilde{\mathcal{X}^0_{\mathcal{V}}}, \mathcal{X}_{\mathcal{E}}), \tilde{\mathcal{X}^0_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;$\mathcal{G}_i = (\mathcal{V}, \mathcal{E}^i, \tilde{\mathcal{X}^i_{\mathcal{V}}}, \mathcal{X}^i_{\mathcal{E}}), \tilde{\mathcal{X}^i_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G}), (\mathcal{E}^i, \mathcal{X}^i_{\mathcal{E}}) \sim \texttt{P}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;Personal opinion&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The real usage of discriminator loss will be to push original &amp;amp; perturbed graph apart, while applying edit distance loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discrepancy with Edit distance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How dissimilar?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Usually, we need to measure the graph distance, such as edit distance.&lt;/p&gt;
&lt;p&gt;Edit distance: number of insertion, deletion, and substitution operations for nodes &amp;amp; edges to transform one graph from another. â†’ NP hard!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But we know the exact number of perturbations for each graphs&lt;/p&gt;
&lt;p&gt;â†’ use it as distance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\mathcal{L}_{edit} = \sum_{i, j} \Big ( \frac{d_i}{e_i} - \frac{d_j}{e_j}\Big )^2 \text{ with } d_i = f_{\text{diff}}(h_{\mathcal{G}_0}, h_{\mathcal{G}_i})$&lt;/p&gt;
&lt;p&gt;$f_{\text{diff}}$ measures the embedding level differences between graphs with &lt;code&gt;L2 norm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;$e_i$: edit distance (number of perturbations)&lt;/p&gt;
&lt;p&gt;The trivial solution for the edit distance loss is $d_i = d_j = 0$. But because of the discriminator loss, this is not possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relative discrepancy learning with other graphs&lt;/p&gt;
&lt;p&gt;Assumption:&lt;/p&gt;
&lt;p&gt;Distance between original and negative graphs in the same batch is larger than the distance between the original and perturbed graphs with some amount of margin.&lt;/p&gt;
&lt;p&gt;Formally,&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{margin} = \sum_{i, j} \max (0, \alpha + d_i - d&amp;rsquo;_j)$&lt;/p&gt;
&lt;p&gt;$d_i$: distance between original and its perturbed graphs&lt;/p&gt;
&lt;p&gt;$d&amp;rsquo;_j$: distance between original and negative graphs&lt;/p&gt;
&lt;p&gt;Intuitively, $\alpha + d_i &amp;lt; d&amp;rsquo;_j$ !&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;overall-loss&#34;&gt;Overall loss&lt;/h3&gt;
&lt;p&gt;$\mathcal{L} = \mathcal{L}_{GD} + \lambda_1 \mathcal{L}_{edit} + \lambda_2 \mathcal{L}_{margin}$&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled4.png&#34;
	width=&#34;2760&#34;
	height=&#34;878&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;314&#34;
		data-flex-basis=&#34;754px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled5.png&#34;
	width=&#34;662&#34;
	height=&#34;656&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled6.png&#34;
	width=&#34;2072&#34;
	height=&#34;640&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/imgs/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;777px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
