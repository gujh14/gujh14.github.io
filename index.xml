<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>JH Gu&#39;s Tech Blog</title>
        <link>https://gujh14.github.io/</link>
        <description>Recent content on JH Gu&#39;s Tech Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 01 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://gujh14.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>About JH Gu</title>
        <link>https://gujh14.github.io/about-jh-gu/</link>
        <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/about-jh-gu/</guid>
        <description>&lt;p&gt;blabla&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Does GNN Pre-training Help Molecular Representation?</title>
        <link>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</link>
        <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/0.png" alt="Featured image of post Does GNN Pre-training Help Molecular Representation?" /&gt;&lt;p&gt;NeurIPS, &amp;lsquo;22
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2207.06010&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/abs/2207.06010&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised pre-training alone &lt;strong&gt;does not&lt;/strong&gt; provide statistically significant improvements over non-pre-trained methods on downstream tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data splits, hand-crafted rich features, or hyperparameters&lt;/strong&gt; can bring significant improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled.png&#34;
	width=&#34;1722&#34;
	height=&#34;582&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled_hu2522057aecca1aa237485e0d3503f9e7_141482_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;710px&#34;
	
&gt;
Pre-train objectives&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised
&lt;ul&gt;
&lt;li&gt;Node prediction&lt;/li&gt;
&lt;li&gt;Context prediction&lt;/li&gt;
&lt;li&gt;Motif prediction&lt;/li&gt;
&lt;li&gt;Contrastive learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supervised
&lt;ul&gt;
&lt;li&gt;Related tasks with label (e.g. ChEMBL dataset)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graph features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Basic
Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1905.12265&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hu et al.&lt;/a&gt;&lt;br&gt;
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1.png&#34;
	width=&#34;1694&#34;
	height=&#34;508&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled1_hu88729ad961e3498c17ab82c4660c440e_117274_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;333&#34;
		data-flex-basis=&#34;800px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich&lt;/p&gt;
&lt;p&gt;Feature set used in &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2007.02835&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rong et al.&lt;/a&gt; This is the superset of basic features.
&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2.png&#34;
	width=&#34;1338&#34;
	height=&#34;1076&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled2_hub6d6462cb2f07779a844e0b6f42f690b_168013_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;124&#34;
		data-flex-basis=&#34;298px&#34;
	
&gt;
In downstream tasks, additional 2d normalized &lt;code&gt;rdNormalizedDescriptors&lt;/code&gt; are used (not in pre-training).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Downstream splits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Scaffold&lt;/p&gt;
&lt;p&gt;Sorts the molecule according to the scaffold, then partition the sorted list into train/valid/test splits. → Deterministic&lt;/p&gt;
&lt;p&gt;Molecules of each set are most different ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Balanced scaffold&lt;/p&gt;
&lt;p&gt;Introduces the randomness in the sorting and splitting stages of Scaffold split.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GNN architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GIN&lt;/li&gt;
&lt;li&gt;GraphSAGE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pre-train dataset&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ZINC15 (self-supervised)&lt;/p&gt;
&lt;p&gt;2 million molecules. Pre-processed following Hu et al.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SAVI (self-supervised)&lt;/p&gt;
&lt;p&gt;1 billion drug-like molecules synthesized by computer simulated reactions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChEMBL (supervised)&lt;/p&gt;
&lt;p&gt;500k drugable molecules with 1,310 prediction target labels from bio-activity assays.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3.png&#34;
	width=&#34;1696&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled3_hu23dfaf19760eb9198a64586f6e9e538d_129521_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;421&#34;
		data-flex-basis=&#34;1012px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4.png&#34;
	width=&#34;1694&#34;
	height=&#34;306&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled4_hub456f2da350b268e245cd11a5535bf94_107470_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;553&#34;
		data-flex-basis=&#34;1328px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5.png&#34;
	width=&#34;1690&#34;
	height=&#34;390&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled5_hu2c1b41f4be72da8a39843fe8bece40ca_127650_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;433&#34;
		data-flex-basis=&#34;1040px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6.png&#34;
	width=&#34;1712&#34;
	height=&#34;308&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6_hu9e3333a7416211da0979291a20928457_104323_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled6_hu9e3333a7416211da0979291a20928457_104323_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;555&#34;
		data-flex-basis=&#34;1334px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7.png&#34;
	width=&#34;1700&#34;
	height=&#34;326&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled7_hufd2c8cd9ddab44b099368583aeb3c4b4_98592_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;521&#34;
		data-flex-basis=&#34;1251px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8.png&#34;
	width=&#34;1702&#34;
	height=&#34;316&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled8_hue724faf0b9e1050d8cd4ed3ab8021048_107066_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;538&#34;
		data-flex-basis=&#34;1292px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9.png&#34;
	width=&#34;1710&#34;
	height=&#34;324&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled9_hu3469e656073a5e47d18db581b35e22f4_102002_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;527&#34;
		data-flex-basis=&#34;1266px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10.png&#34;
	width=&#34;1696&#34;
	height=&#34;328&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled10_hu3e2f5f911381baac558177a0aa61cd89_114788_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;517&#34;
		data-flex-basis=&#34;1240px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11.png&#34;
	width=&#34;1698&#34;
	height=&#34;358&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled11_hucbfacb23d6af299525c858ef04d38582_129938_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;474&#34;
		data-flex-basis=&#34;1138px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12.png&#34;
	width=&#34;1704&#34;
	height=&#34;368&#34;
	srcset=&#34;https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/does-gnn-pre-training-help-molecular-representation/Untitled12_hu98ddd8342e269d06b326bfdd4dd2ec69_121600_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;463&#34;
		data-flex-basis=&#34;1111px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;
&lt;h3 id=&#34;when-pre-training-might-help&#34;&gt;When pre-training might help?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Related &lt;strong&gt;supervised&lt;/strong&gt; pre-training dataset. But not always feasible.&lt;/li&gt;
&lt;li&gt;If the rich features are absent.&lt;/li&gt;
&lt;li&gt;If the downstream split distributions are substantially different.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;when-the-gain-dimishes&#34;&gt;When the gain dimishes?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;If using rich features.&lt;/li&gt;
&lt;li&gt;If don’t have the highly relevant supervisions.&lt;/li&gt;
&lt;li&gt;If the downstream split is balanced.&lt;/li&gt;
&lt;li&gt;If the self-supervised learning dataset lacks diversity.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;why-pre-training-may-not-help-in-some-cases&#34;&gt;Why pre-training may not help in some cases?&lt;/h3&gt;
&lt;p&gt;Some of the pre-training methods (e.g. node label prediction) might be too easy&lt;br&gt;
→ Transfer less knowledge.&lt;/p&gt;
&lt;p&gt;So…&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use rich features&lt;/li&gt;
&lt;li&gt;Use balanced scaffold&lt;/li&gt;
&lt;li&gt;Use related supervised pre-training dataset&lt;/li&gt;
&lt;li&gt;Use difficult pre-training task (for self-supervised pre-training) and use high-quality negative samples.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Graph Self-supervised Learning with Accurate Discrepancy Learning</title>
        <link>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</link>
        <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/0.png" alt="Featured image of post Graph Self-supervised Learning with Accurate Discrepancy Learning" /&gt;&lt;p&gt;NeurIPS, &amp;lsquo;22,&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=SgZ-glWWUlq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://openreview.net/forum?id=SgZ-glWWUlq&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Authors proposed a framework called D-SLA that aims to learn the exact discrepancy between the original and the perturbed graphs.&lt;/li&gt;
&lt;li&gt;Three major components
&lt;ol&gt;
&lt;li&gt;Learn to distinguish whether each graph is the original graph or the perturbed one.&lt;/li&gt;
&lt;li&gt;Capture the amount of discrepancy for each perturbed graph (using edit distance)&lt;/li&gt;
&lt;li&gt;Learn relative discrepancy with other graphs&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;h3 id=&#34;graph-neural-networks-gnn&#34;&gt;Graph Neural Networks (GNN)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Aggregate the features from its neighbors&lt;/li&gt;
&lt;li&gt;Combining the aggregated message&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variants of Update &amp;amp; Aggregate functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Graph Convolution Network (GCN)&lt;/p&gt;
&lt;p&gt;General convolution operation + Mean aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GraphSAGE&lt;/p&gt;
&lt;p&gt;Concatenate representations of neighbors with its own representation when updating&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Attention Network (GAT)&lt;/p&gt;
&lt;p&gt;Considers the relative importance among neighboring nodes when aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Isomorphism Network (GIN)&lt;/p&gt;
&lt;p&gt;Sum aggregation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;self-supervised-learning-for-graphs-gsl&#34;&gt;Self-supervised learning for graphs (GSL)&lt;/h3&gt;
&lt;p&gt;Aims to learn a good representation of the graphs in an unsupervised manner.&lt;/p&gt;
&lt;p&gt;→ Transfer this knowledge to downstream tasks.&lt;/p&gt;
&lt;p&gt;Most prevalent framework for GSL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Predictive learning (PL)&lt;/p&gt;
&lt;p&gt;Aims to learn &lt;strong&gt;contextual relationships&lt;/strong&gt; by predicting sub-graphical features (nodes, edges, subgraphs)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;predict the attributes of masked nodes&lt;/li&gt;
&lt;li&gt;predict the presence of an edge or a path&lt;/li&gt;
&lt;li&gt;predict the generative sequence, contextual property, and motifs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But predictive learning &lt;strong&gt;may not capture the global structures and/or semantics of graphs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled.png&#34;
	width=&#34;896&#34;
	height=&#34;520&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled_huff270fcc5aeca6685caf1879e044c99c_227289_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrastive learning (CL)&lt;/p&gt;
&lt;p&gt;Aims to &lt;strong&gt;capture global level information.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Early CL learn the similarity between the entire graph and its substructure.&lt;/li&gt;
&lt;li&gt;Others include attribute masking, edge perturbation, and subgraph sampling.&lt;/li&gt;
&lt;li&gt;Recent CL adversarial methods generate positive examples either by adaptively removing the edges or by adjusting the attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But CL &lt;strong&gt;may not distinguish two topologically similar graphs yet having completely different properties.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1.png&#34;
	width=&#34;894&#34;
	height=&#34;526&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled1_hu2f022890e791016794b0ba84351f912a_250914_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2.png&#34;
	width=&#34;946&#34;
	height=&#34;384&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled2_hu5b683b5549a725d0a4cfb0bcb47c4b83_188133_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Minimize $\mathcal{L}_{CL} = - \log \frac{f_{\text{sim}} (h_{\mathcal{G}_i}, h_{\mathcal{G}_j})}{\sum_{\mathcal{G}&amp;rsquo;, \mathcal{G&amp;rsquo; \neq \mathcal{G}_0}}f_{\text{sim}}(h_{\mathcal{G}_i}, h_{\mathcal{G}&amp;rsquo;})}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{G}_0$: original graph&lt;/li&gt;
&lt;li&gt;$\mathcal{G}_i, \mathcal{G}_j$: perturbed graphs&lt;/li&gt;
&lt;li&gt;$\mathcal{G}&amp;rsquo;$: other graph in the same batch with the $\mathcal{G}_0$, a.k.a. negative graph&lt;/li&gt;
&lt;li&gt;positive pair: $(\mathcal{G}_i, \mathcal{G}_j)$; negative pair: $(\mathcal{G}_i, \mathcal{G}&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;$f_\text{sim}$: similarity function between two graphs → $L_2$ distance or cosine similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→ similarity of positive pair $\uparrow$, similarity of negative pair $\downarrow$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;discrepancy-learning&#34;&gt;Discrepancy Learning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3.png&#34;
	width=&#34;1312&#34;
	height=&#34;402&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled3_hu733a3810c757eb627bd173cc2c52ec22_403552_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;326&#34;
		data-flex-basis=&#34;783px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Discriminate original vs perturbed&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perturbed graph could be semantically incorrect!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;→ Embed perturbed graph apart from original.&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{GD} = - \log \Big (\frac{e^{S_0}}{e^{S_0} + \sum_{i \geq 1}e^{S_i}} \Big ) \text{ with } S = f_S(h_{\mathcal{G}})$&lt;/p&gt;
&lt;p&gt;Intuitively,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;large value of $e^{S_0}$ for the original graph&lt;/li&gt;
&lt;li&gt;small value of $e^{S_i}$ for the perturbed graphs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How to perturb?&lt;/p&gt;
&lt;p&gt;Aim at perturbed graph to be semantically incorrect&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Remove or add a small number of edges&lt;/p&gt;
&lt;p&gt;Manipulate the edge set by removing existing edges  + adding new edges on $\mathcal{X}_\mathcal{E}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mask node attributes&lt;/p&gt;
&lt;p&gt;Randomly mask the node attributes on $\mathcal{X}_\mathcal{V}$ for both original and perturbed graphs&lt;/p&gt;
&lt;p&gt;(to make it more difficult to distinguish between them)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\mathcal{G}_0 = (\mathcal{V}, \mathcal{E}, \tilde{\mathcal{X}^0_{\mathcal{V}}}, \mathcal{X}_{\mathcal{E}}), \tilde{\mathcal{X}^0_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;$\mathcal{G}_i = (\mathcal{V}, \mathcal{E}^i, \tilde{\mathcal{X}^i_{\mathcal{V}}}, \mathcal{X}^i_{\mathcal{E}}), \tilde{\mathcal{X}^i_{\mathcal{V}}} \sim \texttt{M}(\mathcal{G}), (\mathcal{E}^i, \mathcal{X}^i_{\mathcal{E}}) \sim \texttt{P}(\mathcal{G})$&lt;/p&gt;
&lt;p&gt;Personal opinion&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The real usage of discriminator loss will be to push original &amp;amp; perturbed graph apart, while applying edit distance loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discrepancy with Edit distance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How dissimilar?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Usually, we need to measure the graph distance, such as edit distance.&lt;/p&gt;
&lt;p&gt;Edit distance: number of insertion, deletion, and substitution operations for nodes &amp;amp; edges to transform one graph from another. → NP hard!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But we know the exact number of perturbations for each graphs&lt;/p&gt;
&lt;p&gt;→ use it as distance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\mathcal{L}_{edit} = \sum_{i, j} \Big ( \frac{d_i}{e_i} - \frac{d_j}{e_j}\Big )^2 \text{ with } d_i = f_{\text{diff}}(h_{\mathcal{G}_0}, h_{\mathcal{G}_i})$&lt;/p&gt;
&lt;p&gt;$f_{\text{diff}}$ measures the embedding level differences between graphs with &lt;code&gt;L2 norm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;$e_i$: edit distance (number of perturbations)&lt;/p&gt;
&lt;p&gt;The trivial solution for the edit distance loss is $d_i = d_j = 0$. But because of the discriminator loss, this is not possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relative discrepancy learning with other graphs&lt;/p&gt;
&lt;p&gt;Assumption:&lt;/p&gt;
&lt;p&gt;Distance between original and negative graphs in the same batch is larger than the distance between the original and perturbed graphs with some amount of margin.&lt;/p&gt;
&lt;p&gt;Formally,&lt;/p&gt;
&lt;p&gt;$\mathcal{L}_{margin} = \sum_{i, j} \max (0, \alpha + d_i - d&amp;rsquo;_j)$&lt;/p&gt;
&lt;p&gt;$d_i$: distance between original and its perturbed graphs&lt;/p&gt;
&lt;p&gt;$d&amp;rsquo;_j$: distance between original and negative graphs&lt;/p&gt;
&lt;p&gt;Intuitively, $\alpha + d_i &amp;lt; d&amp;rsquo;_j$ !&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;overall-loss&#34;&gt;Overall loss&lt;/h3&gt;
&lt;p&gt;$\mathcal{L} = \mathcal{L}_{GD} + \lambda_1 \mathcal{L}_{edit} + \lambda_2 \mathcal{L}_{margin}$&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4.png&#34;
	width=&#34;2760&#34;
	height=&#34;878&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled4_hu61ce1efc03ade92431ecba0566b173fe_1254349_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;314&#34;
		data-flex-basis=&#34;754px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5.png&#34;
	width=&#34;662&#34;
	height=&#34;656&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled5_hub614ec3849a1c45ba1bddf42f077afb8_259131_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6.png&#34;
	width=&#34;2072&#34;
	height=&#34;640&#34;
	srcset=&#34;https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/graph-self-supervised-learning-with-accurate-discrepancy-learning/Untitled6_hua1d295acff7e146071f146ac8c9b5420_722837_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;777px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>PhysChem: Deep Molecular Representation Learning via Fusing Physical and Chemical Information</title>
        <link>https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/</link>
        <pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1.png" alt="Featured image of post PhysChem: Deep Molecular Representation Learning via Fusing Physical and Chemical Information" /&gt;&lt;p&gt;NeurIPS Poster, &amp;lsquo;21,&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2112.04624&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/abs/2112.04624&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Used physicist network (PhysNet) and chemist network (ChemNet) simultaneously, and each network shares information to solve individual tasks.&lt;/li&gt;
&lt;li&gt;PhysNet: Neural physical engine. Mimics molecular dynamics to predict conformation.&lt;/li&gt;
&lt;li&gt;ChemNet: Message passing network for chemical &amp;amp; biomedical property prediction.&lt;/li&gt;
&lt;li&gt;Molecule without 3D conformation can be inferred during test time.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Molecular representation learning:&lt;br&gt;
Embedding molecules into latent space for downstream tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Physical Engines&lt;br&gt;
Neural networks are capable of learning annotated potentials and forces in particle systems.&lt;br&gt;
HamNet proposed a neural physical engine that operated on a generalized space, where positions and momentums of atoms were defined as high-dimensional vectors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-task learning&lt;br&gt;
Sharing representations for different but related tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model fusion&lt;br&gt;
Merging different models on identical tasks to improve performance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;notation&#34;&gt;Notation&lt;/h2&gt;
&lt;p&gt;Graph $\mathcal{M} = (\mathcal{V}, \mathcal{E}, n, m, \mathbf{X}^v, \mathbf{X}^e)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{V}$: set of $n$ atoms&lt;/li&gt;
&lt;li&gt;$\mathcal{E}$: set of $m$ chemical bonds&lt;/li&gt;
&lt;li&gt;$\mathbf{X}^v \in \mathbb{R}^{n \times d_v} = (x^v_1, &amp;hellip;, x^v_n)^\top$: matrix of atomic features&lt;/li&gt;
&lt;li&gt;$\mathbf{X}^e \in \mathbb{R}^{m \times d_e} = (x^e_1, &amp;hellip;, x^e_m)^\top$: matrix of bond features&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1.png&#34;
	width=&#34;2000&#34;
	height=&#34;709&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1_hu614a3ffe516a8cd557a8bbd359513341_952945_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physchem_1_hu614a3ffe516a8cd557a8bbd359513341_952945_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;282&#34;
		data-flex-basis=&#34;677px&#34;
	
&gt;
Figure 1. PhysChem Architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Initializer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input: atomic features, bond features (from RDKit)&lt;/li&gt;
&lt;li&gt;Layer: fully connected layers&lt;/li&gt;
&lt;li&gt;Output:&lt;/li&gt;
&lt;li&gt;bond states, atom states for ChemNet&lt;br&gt;
$v^{(0)}_i = \text{FC}(x^v_i), i\in \mathcal{V}$&lt;br&gt;
$e^{(0)}_{i,j} = \text{FC}(x^e_{i,j}), (i, j)\in \mathcal{E}$&lt;/li&gt;
&lt;li&gt;atom positions, atomic momenta for PhysNet&lt;br&gt;
Bond strength adjacency matrix&lt;br&gt;
$$A(i,j)=\begin{cases}0, &amp;amp; \text{if $(i,j) \notin \mathcal{E}$} \\ \text{FC}_{\text{sigmoid}}(x^e_{i,j}), &amp;amp; \text{if $(i,j) \in \mathcal{E}$} \end{cases}$$
$\tilde{V} = \text{GCN}(A, V^{(0)})$&lt;br&gt;
${ (q^{(0)}_i \oplus p^{(0)}_i)}  = \text{LSTM}({\tilde{v}_i}), i \in \mathcal{V}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PhysNet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PhysNet is inspired by &lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=q-cnWaaoUTH&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HamNet&lt;/a&gt;.&lt;br&gt;
HamNet showed that neural networks can simulate molecular dynamics for conformation prediction.&lt;/li&gt;
&lt;li&gt;Directly parameterize the forces between each pair of atoms.&lt;/li&gt;
&lt;li&gt;Consider the effects of chemical interactions(e.g. bond types) by cooperating with ChemNet’s bond states.&lt;/li&gt;
&lt;li&gt;Introduces torsion forces.&lt;/li&gt;
&lt;li&gt;Output: 3D conformation
&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet.jpeg&#34;
	width=&#34;1424&#34;
	height=&#34;1000&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet_huc04268559fc6ac467b55debd1d11cbcb_463344_480x0_resize_q75_box.jpeg 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/physnet_huc04268559fc6ac467b55debd1d11cbcb_463344_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChemNet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ChemNet modifies MPNN(message passing neural network) for molecular representation learning.&lt;/li&gt;
&lt;li&gt;Output: Molecule representation
&lt;img src=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet.jpeg&#34;
	width=&#34;1598&#34;
	height=&#34;1000&#34;
	srcset=&#34;https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet_huea3837eddd924d917074e41bba2e849a_561970_480x0_resize_q75_box.jpeg 480w, https://gujh14.github.io/p/physchem-deep-molecular-representation-learning-via-fusing-physical-and-chemical-information/chemnet_huea3837eddd924d917074e41bba2e849a_561970_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;loss&#34;&gt;Loss&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$L_{\text{phys}}$: Conn-k loss for Conformation prediction (PhysNet)&lt;/p&gt;
&lt;p&gt;$k$-hop connectivity loss&lt;/p&gt;
&lt;p&gt;$L_{\text{Conn}-k}(\hat{\mathbf{R}}, \mathbf{R}) = |\frac{1}{n} \hat{\mathbf{C}}^{(k)} \odot (\hat{\mathbf{D}} - \mathbf{D}) \odot (\hat{\mathbf{D}} - \mathbf{D}) |_{F}$&lt;/p&gt;
&lt;p&gt;$\odot$: element-wise product&lt;/p&gt;
&lt;p&gt;$| \cdot |$: Frobenius norm&lt;/p&gt;
&lt;p&gt;$(\hat{\mathbf{D}} - \mathbf{D})$ : distance matrix of the real and predicted conformations $(\hat{\mathbf{R}} - \mathbf{R})$&lt;/p&gt;
&lt;p&gt;$\hat{\mathbf{C}}^{(k)}$: normalized $k$-hop connectivity matrix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$L_{\text{chem}}$: MAE or Cross entropy loss for Property prediction (ChemNet)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Total loss&lt;/p&gt;
&lt;p&gt;$L_{\text{total}} = \lambda L_{\text{phys}} + L_{\text{chem}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Checkpoints&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Is Conn-k loss generally used in other conformation prediction models?&lt;/p&gt;
&lt;p&gt;No! But seems related to local distance loss.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is triplet descriptor generally used in other models?&lt;/p&gt;
&lt;p&gt;No!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>CMap based Drug Repositioning of BTZ to reverse the metastatic effect of GALNT14 in lung cancer</title>
        <link>https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/</link>
        <pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/</guid>
        <description>&lt;img src="https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_0.png" alt="Featured image of post CMap based Drug Repositioning of BTZ to reverse the metastatic effect of GALNT14 in lung cancer" /&gt;&lt;p&gt;Oncogene, &amp;lsquo;20&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.nature.com/articles/s41388-020-1316-2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.nature.com/articles/s41388-020-1316-2&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;In-silico approach based on CMap to identify drug candidates for lung cancer metastasis&lt;/li&gt;
&lt;li&gt;Revealed the underlying mechanisms of undruggable target (GALNT14) and targeted the downstream transcription factor&lt;/li&gt;
&lt;li&gt;Repositioned drug: BTZ (Bortezomib)&lt;/li&gt;
&lt;li&gt;Integrated multiple independent expression signatures from cancer patients (TCGA), genetic perturbations(knock-down or overexpression), and drug treatment (CMap)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GALNT14: a putative driver of lung cancer metastasis, leading to poor survival &amp;amp; has poor druggability.&lt;/li&gt;
&lt;li&gt;Bortezomib: drug used for multiple myeloma and mantle cell lymphoma&lt;/li&gt;
&lt;li&gt;CMap: a collection of genome wide expression profiles of cell lines treated with &amp;gt; 20,000 chemicals&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-results&#34;&gt;Main Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_1.png&#34;
	width=&#34;1024&#34;
	height=&#34;1528&#34;
	srcset=&#34;https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_1_hu6d4a003a2f6221a0fe806f7889e0f77f_1360011_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_1_hu6d4a003a2f6221a0fe806f7889e0f77f_1360011_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;67&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;
Figure 1. GALNT14 as a putative molecular target for lung cancer metastasis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1a. TCGA Lung adenocarcinoma cohort의 516명 lung cancer 환자의 transcriptome data.&lt;/li&gt;
&lt;li&gt;1b. relapse-free survival / DEG 분석에서 7개의 gene들이 검출되었고, 그 7개의 gene의 expression이 높은 group, 낮은 group으로 분류.&lt;/li&gt;
&lt;li&gt;1c. metastasis와 tumor signature가 high-expression group에서 enrich 되었음.&lt;/li&gt;
&lt;li&gt;1d. GALNT14만 단독으로 보아도 metastasis와 tumor 에서 enrich 되어 있음을 알 수 있음.&lt;/li&gt;
&lt;li&gt;1e, 1f. GALNT14이 각각 metastatic potential과 tumorigenic potential이 있다는 in vivo 실험 결과.&lt;/li&gt;
&lt;li&gt;1g. Metastatic lung cancer cell이 non-metastatic cancer보다 GALNT14 depletion에 더 vulnerable.&lt;/li&gt;
&lt;li&gt;1h. GALNT14이 survival에 분명한 negative correlation을 보임.&lt;br&gt;
이것으로 미루어보아, GALNT14이 lung cancer metastasis의 promising molecular target이라는 것을 알 수 있음.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_2.png&#34;
	width=&#34;946&#34;
	height=&#34;1304&#34;
	srcset=&#34;https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_2_hu005e6e010ae2c58e20e9931e08cc1b64_761825_480x0_resize_box_3.png 480w, https://gujh14.github.io/p/cmap-based-drug-repositioning-of-btz-to-reverse-the-metastatic-effect-of-galnt14-in-lung-cancer/cmap_2_hu005e6e010ae2c58e20e9931e08cc1b64_761825_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Image 2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;72&#34;
		data-flex-basis=&#34;174px&#34;
	
&gt;
Figure 5. In vivo validation of the anti-metastatic effect of BTZ.
BTZ의 anti-migration, anti-invasion effect를 in vitro level에서 확인한 뒤 in vivo에서 cancer metastasis efficacy를 확인한 실험 결과&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5a. 쥐의 꼬리 정맥으로 H460 lung cancer cell을 주입하여 local metastasis를 유도하고 control 군, BTZ 처리군, CFZ 처리군으로 구분하였음.&lt;/li&gt;
&lt;li&gt;5b. BTZ, CFZ의 proteasome inhibition을 확인하기 위해 혈액에서 proteasome activity를 측정한 결과. 상당히 줄어들었음을 알 수 있음. P.C. 는 positive control&lt;/li&gt;
&lt;li&gt;5c. Body weight 정보. 항암제 처리로 인해 다른 조직 등에 dramatic한 영향은 없었음.&lt;/li&gt;
&lt;li&gt;5d. Lung cancer로 metastasis 유무 사진. Vehicle과 CFZ는 상당부분 Metastasis가 일어난 것을 볼 수 있지만 BTZ는 6개 중 1개만 미약하게 metastasis 발생.&lt;/li&gt;
&lt;li&gt;5e. H&amp;amp;E staining 후의 lung image&lt;/li&gt;
&lt;li&gt;5f. tumor nodule size의 average. BTZ는 매우 작음.&lt;/li&gt;
&lt;li&gt;5g. tumor nodule의 수 분포. BTZ 매우 적음.&lt;/li&gt;
&lt;li&gt;5h. proteasome activity 차이&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Unlike other studies that used CMap, they focused exclusively on a target gene related to a pertinent phenotype and identified BTZ as a drug candidate with novel anti-metastatic effects.&lt;/li&gt;
&lt;li&gt;In pathway level, the most enriched pathway was TGF￼ signaling, and they also identified the GALNT14-TGF￼ signature, which has invasive properties that are attenuated by BTZ.&lt;/li&gt;
&lt;li&gt;They integrated multiple independent expression signatures from cancer patients(TCGA), genetic perturbations(knock-down or overexpression), and drug treatment(CMap).&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Archives</title>
        <link>https://gujh14.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>Links</title>
        <link>https://gujh14.github.io/links/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/links/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;links&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub is the world&amp;#39;s largest software development platform.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://www.typescriptlang.org&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ts-logo-128.jpg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Search</title>
        <link>https://gujh14.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://gujh14.github.io/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
